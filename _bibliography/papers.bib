@INPROCEEDINGS{9696941,
  author={Wang, Yan and Zhong, Wanxia and Su, Hang and Zheng, Fujiang and Pang, Yiran and Wen, Hongchuan and Cai, Kun},
  booktitle={2021 IEEE International Conference on Emergency Science and Information Technology (ICESIT)}, 
  title={An Improved MVCNN for 3D Shape Recognition}, 
  year={2021},
  volume={},
  number={},
  pages={469-472},
  abstract={The multi-view convolutional neural network architecture represented by MVCNN has achieved great success in 3D shape recognition. Taking the MVCNN architecture as the research goal, this paper proposes a novel 3D shape recognition convolutional neural network Attention-MVCNN that integrates channel attention mechanism, residual structure and Mish activation function. The channel attention machine is used to make the feature extraction network for Attention-MVCNN, which can reduce the feature redundancy caused by traditional convolution. The residual structure can reduce the network over-fitting problem and achieve better gradient information, thereby improving the performance of Attention-MVCNN. We replace the activation function in the Attention-MVCNN network with Mish, a self-regular non-monotonic neural activation function. The smooth activation function allows better information to penetrate the neural network, resulting in better accuracy and generalization. Experiments show that the improved Attention-MVCNN attains the competitive results on ModelNet40 dataset.},
  keywords={Solid modeling;Three-dimensional displays;Image recognition;Shape;Redundancy;Neural networks;Feature extraction;3D shape recognition;Attention mechanism;Residual structure;Mish function},
  doi={10.1109/ICESIT53460.2021.9696941},
  ISSN={},
  month={Nov},
  google_scholar_id={u-x6o8ySG0sC},
  selected=true}
---
@ARTICLE{9964179,
  author={Zhou, Wei and Zheng, Fujian and Yin, Gang and Pang, Yiran and Yi, Jun},
  journal={IEEE Transactions on Instrumentation and Measurement}, 
  title={YOLOTrashCan: A Deep Learning Marine Debris Detection Network}, 
  year={2023},
  volume={72},
  number={},
  pages={1-12},
  abstract={Monitoring marine debris has long been a challenging issue owing to the complex and changeable underwater environment. To fast and accurately detect marine debris, in this article, a novel object detection network termed as YOLOTrashCan is proposed for detecting underwater marine debris. The YOLOTrashCan model consists of feature enhancement and feature fusion. In the feature enhancement part, the ECA_DO-Conv_CSPDarknet53 backbone, which combines efficient channel attention (ECA) module and depthwise over-parameterized convolutional (DO-Conv), is proposed to extract the depth semantic features of marine debris. In the feature fusion part, the DPMs_PixelShuffle_PANET module is presented to improve the detection ability for marine debris, where dilated parallel modules (DPMs) with multiscale dilated rate are designed as enhanced feature modules for different scale objects of marine debris. Notably, the size of the network is only 214 MB using the DPMs’ method. Extensive experiments and thorough analysis are validated on the TrashCan 1.0 dataset. Experimental results show that the proposed algorithm not only improves the detection accuracy of underwater marine debris but also reduces the size of the network model.},
  keywords={Feature extraction;Deep learning;Object detection;Convolution;Plastics;Educational robots;Surface morphology;Dilated convolution;efficient channel attention (ECA);marine debris;multiscale;object detection},
  doi={10.1109/TIM.2022.3225044},
  ISSN={1557-9662},
  month={},
  google_scholar_id={d1gkVwhDpl0C},
  selected=true}
---
@ARTICLE{10004701,
  author={Zhou, Wei and Min, Xuanlin and Zhao, Yiheng and Pang, Yiran and Yi, Jun},
  journal={IEEE Transactions on Biometrics, Behavior, and Identity Science}, 
  title={A Multi-Scale Spatio-Temporal Network for Violence Behavior Detection}, 
  year={2023},
  volume={5},
  number={2},
  pages={266-276},
  abstract={Violence behavior detection has played an important role in computer vision, its widely used in unmanned security monitoring systems, Internet video filtration, etc. However, automatically detecting violence behavior from surveillance cameras has long been a challenging issue due to the real-time and detection accuracy. In this brief, a novel multi-scale spatio-temporal network termed as MSTN is proposed to detect violence behavior from video stream. To begin with, the spatio-temporal feature extraction module (STM) is developed to extract the key features between foreground and background of the original video. Then, temporal pooling and cross channel pooling are designed to obtain short frame rate and long frame rate from STM, respectively. Furthermore, short-time building (STB) branch and long-time building (LTB) branch are presented to extract the violence features from different spatio-temporal scales, where STB module is used to capture the spatial feature and LTB module is used to extract useful temporal feature for video recognition. Finally, a Trans module is presented to fuse the features of STB and LTB through lateral connection operation, where LTB feature is compressed into STB to improve the accuracy. Experimental results show the effectiveness and superiority of the proposed method on computational efficiency and detection accuracy.},
  keywords={Feature extraction;Behavioral sciences;Kernel;Visualization;Data mining;Buildings;Biometrics (access control);Violent behavior detection;deep learning;spatio-temporal;convolutional neuronal network},
  doi={10.1109/TBIOM.2022.3233399},
  ISSN={2637-6407},
  month={April},
  google_scholar_id={9yKSN-GCB0IC},
  selected=true}
---
@ARTICLE{10221866,
  author={Pang, Yiran and Ni, Zhen and Zhong, Xiangnan},
  journal={IEEE Internet of Things Journal}, 
  title={Federated Learning for Crowd Counting in Smart Surveillance Systems}, 
  year={2024},
  volume={11},
  number={3},
  pages={5200-5209},
  abstract={Crowd counting in smart surveillance systems plays a crucial role in Internet of Things (IoT) and smart cities, and can affect various aspects, such as public safety, crowd management, and urban planning. Using surveillance data to centrally train a crowd counting model raises significant privacy concerns. Traditional methods try to alleviate the concern by reducing the focus on individuals, but the concern still needs to be thoroughly resolved. In this work, we develop a horizontal federated learning (HFL) framework to train the crowd counting models which can preserve privacy simultaneously. This framework enables the smart surveillance system to learn from model aggregation without accessing the private data stored on local devices. Therefore, it eliminates the need for video data transmission, reduces communication costs, and avoids raw data leakage. Due to the lack of federated learning (FL) crowd counting data sets, we design four non-independent and identically distributed (non-IID) partitioning strategies, including feature-skew, quantity-skew, scene-skew, and time-skew, to simulate real-world FL scenarios. In addition, we present an efficient fully convolutional network (e-FCN) for each client to demonstrate the practical applicability of the proposed framework. The e-FCN adopts an encoder-decoder architecture with fewer parameters, making it communication-friendly and easier to train. This design can achieve competitive performance compared to more complex models in surveillance crowd counting in literature. Finally, we evaluate the proposed HFL framework with e-FCN under our skew strategies on multiple real-world data sets, including crowd surveillance, ShanghaiTech PartB, WorldExpo’10, FDST, CityUHK-X, UCSD, and MALL. Extensive experiments allow us to present our developed Federated Crowd Counting benchmark as a reference for future research and provide guidance for FL algorithm selection in smart surveillance system deployment.},
  keywords={Surveillance;Data models;Task analysis;Servers;Training;Internet of Things;Data privacy;Convolutional neural networks (CNNs);crowd counting;data partition;federated learning (FL);non-independent and identically distributed (non-IID) partitioning benchmarks;smart surveillance system},
  doi={10.1109/JIOT.2023.3305933},
  ISSN={2327-4662},
  month={Feb},
  google_scholar_id={2osOgNQ5qMEC},
  selected=true}
---
@article{wang2023counting,
  title={Counting manatee aggregations using deep neural networks and Anisotropic Gaussian Kernel},
  author={Wang, Zhiqiang and Pang, Yiran and Ulus, Cihan and Zhu, Xingquan},
  journal={Scientific Reports},
  volume={13},
  number={1},
  pages={19793},
  year={2023},
  publisher={Nature Publishing Group UK London},
  doi={10.1038/s41598-023-45507-3},
  abstract={Manatees are aquatic mammals with voracious appetites. They rely on sea grass as the main food source, and often spend up to eight hours a day grazing. They move slow and frequently stay in groups (i.e. aggregations) in shallow water to search for food, making them vulnerable to environment change and other risks. Accurate counting manatee aggregations within a region is not only biologically meaningful in observing their habit, but also crucial for designing safety rules for boaters, divers, etc., as well as scheduling nursing, intervention, and other plans. In this paper, we propose a deep learning based crowd counting approach to automatically count number of manatees within a region, by using low quality images as input. Because manatees have unique shape and they often stay in shallow water in groups, water surface reflection, occlusion, camouflage etc. making it difficult to accurately count manatee numbers. To address the challenges, we propose to use Anisotropic Gaussian Kernel (AGK), with tunable rotation and variances, to ensure that density functions can maximally capture shapes of individual manatees in different aggregations. After that, we apply AGK kernel to different types of deep neural networks primarily designed for crowd counting, including VGG, SANet, Congested Scene Recognition network (CSRNet), MARUNet etc. to learn manatee densities and calculate number of manatees in the scene. By using generic low quality images extracted from surveillance videos, our experiment results and comparison show that AGK kernel based manatee counting achieves minimum Mean Absolute Error (MAE) and Root Mean Square Error (RMSE). The proposed method works particularly well for counting manatee aggregations in environments with complex background.},
  google_scholar_id={qjMakFHDy7sC},
  selected=true}
---
@ARTICLE{10311097,
  author={Yi, Jun and Pang, Yiran and Zhou, Wei and Zhao, Meng and Zheng, Fujian},
  journal={IEEE Transactions on Intelligent Transportation Systems}, 
  title={A Perspective-Embedded Scale-Selection Network for Crowd Counting in Public Transportation}, 
  year={2024},
  volume={25},
  number={5},
  pages={3420-3432},
  abstract={Crowd counting in congested urban transport systems is a highly challenging task for computer vision and deep learning due to several factors such as mutual occlusion, perspective change, and large-scale variations. In this paper, a novel perspective-embedded scale-selection multi-column network named PESSNet is proposed for crowd counting and high-quality density maps generation. The proposed method aligns the branches to various scales by leveraging different receptive fields, and utilizes perspective parameters to adjust the sensitivity of each branch to different perspective areas in the scene. Specifically, the PESSNet consists of four key components: 1) feature pyramid network (FPN) fuses multi-stage features extracted from the backbone network; 2) scale-selection dilated layer (SSDL) extracts features by using different dilated convolution kernels for each stage; 3) perspective-embedded fusion layer (PEFL) encodes the spatial perspective relationships across all feature levels into the network and provides a more effective fine-grained weight map; and 4) density maps generator (DMG) employs deconvolution layer as a decoder to generate high-quality density maps. The above strategies maximizes the ability of multi-column network to extract the features of instances with various scales. Extensive experiments on seven crowd counting benchmark datasets, JHU-CROWD, ShanghaiTech, UCF-QNRF, ShanghaiTechRGBD, WorldEXPO’10, TRANCOS, and NWPU-Crowd indicate that PESSNet achieves reliable recognition performance and high robustness in difference crowd counting.},
  keywords={Feature extraction;Convolutional neural networks;Fuses;Estimation;Decoding;Training;Crowdsensing;Crowd counting;multi-column network;perspective analysis;dilated convolution},
  doi={10.1109/TITS.2023.3328000},
  ISSN={1558-0016},
  month={May},
  google_scholar_id={UeHWp8X0CEIC},
  selected=true}
---
@article{wang2023large,
  title={Large language models are zero-shot text classifiers},
  author={Wang, Zhiqiang and Pang, Yiran and Lin, Yanbin},
  journal={arXiv preprint arXiv:2312.01044},
  year={2023},
  abstract={Retrained large language models (LLMs) have become extensively used across various sub-disciplines of natural language processing (NLP). In NLP, text classification problems have garnered considerable focus, but still faced with some limitations related to expensive computational cost, time consumption, and robust performance to unseen classes. With the proposal of chain of thought prompting (CoT), LLMs can be implemented using zero-shot learning (ZSL) with the step by step reasoning prompts, instead of conventional question and answer formats. The zero-shot LLMs in the text classification problems can alleviate these limitations by directly utilizing pretrained models to predict both seen and unseen classes. Our research primarily validates the capability of GPT models in text classification. We focus on effectively utilizing prompt strategies to various text classification scenarios. Besides, we compare the performance of zero shot LLMs with other state of the art text classification methods, including traditional machine learning methods, deep learning methods, and ZSL methods. Experimental results demonstrate that the performance of LLMs underscores their effectiveness as zero-shot text classifiers in three of the four datasets analyzed. The proficiency is especially advantageous for small businesses or teams that may not have extensive knowledge in text classification.},
  keywords={Zero-shot text classification, large language models, text classification, Chat GPT-4, Llama2.},
  doi={10.48550/arXiv.2312.01044},
  google_scholar_id={IjCSPb-OGe4C},
  selected=true
}
---
@article{ZHOU2024106141,
    title = {MSDCNN: A multiscale dilated convolution neural network for fine-grained 3D shape classification},
    journal = {Neural Networks},
    volume = {172},
    pages = {106141},
    year = {2024},
    issn = {0893-6080},
    doi = {10.1016/j.neunet.2024.106141},
    url = {https://www.sciencedirect.com/science/article/pii/S0893608024000571},
    author = {Wei Zhou and Fujian Zheng and Yiheng Zhao and Yiran Pang and Jun Yi},
    keywords = {Multi-view 3D shape classification, Fine-grained classification, Dilated convolution, Label smoothing, Attention mechanism},
    abstract = {Multi-view deep neural networks have shown excellent performance on 3D shape classification tasks. However, global features aggregated from multiple views data often lack content information and spatial relationship, which leads to difficult identification the small variance among subcategories in the same category. To solve this problem, in this paper, a novel multiscale dilated convolution neural network termed as MSDCNN is proposed for multi-view fine-grained 3D shape classification. Firstly, a sequence of views are rendered from 12-viewpoints around the input 3D shape by the sequential view capturing module. Then, the first 22 convolution layers of ResNeXt50 is employed to extract the semantic features of each view, and a global mixed feature map is obtained through the element-wise maximum operation of the 12 output feature maps. Furthermore, attention dilated module (ADM), which combines four concatenated attention dilated block (ADB), is designed to extract larger receptive field features from global mixed feature map to enhance context information among the views. Specifically, each ADB is consisted by an attention mechanism module and a dilated convolution with different dilation rates. In addition, prediction module with label smoothing is proposed to classify features, which contains 3 × 3 convolution and adaptive average pooling. The performance of our method is validated experimentally on the ModelNet10, ModelNet40 and FG3D datasets. Experimental results demonstrate the effectiveness and superiority of the proposed MSDCNN framework for 3D shape fine-grained classification.},
    google_scholar_id={Tyk-4Ss8FVUC},
    selected=true}

---
@ARTICLE{10498080,
  author={Min, Xuanlin and Zhou, Wei and Hu, Rui and Wu, Yinyue and Pang, Yiran and Yi, Jun},
  journal={IEEE Internet of Things Journal}, 
  title={LWUAVDet: A Lightweight UAV Object Detection Network on Edge Devices}, 
  year={2024},
  volume={11},
  number={13},
  pages={24013-24023},
  abstract={Real-time object detection on unmanned aerial vehicles (UAVs) poses a challenging issue due to the limited computing resources of edge devices. To address this problem, we propose a novel lightweight object detection network named LWUAVDet for real-time UAV applications. The detector comprises three core components: E-FPN, PixED Head, and Aux Head. First, we develop an extended and refined topology in the Neck layer, called E-FPN, to enhance the multiscale representation of each stage and alleviate the aliasing effect caused by the repetitive feature fusion of the Neck. Second, we propose a pixel encoder and decoder for dimension exchange between space and channel to achieve flexible and effective feature extraction in the Head layer, named PixED Head. Furthermore, Aux Head for the auxiliary task merely using the Head layer is presented for online distillation to enhance feature representation. Specially, in Aux Head, we introduce the weighted sum of Focal Loss and complete intersection over union loss for the cost matrix of the sample assigner to alleviate category imbalance and aspect ratio imbalance of the UAV data. The performance of our LWUAVDet is validated experimentally on the NVIDIA Jetson Xavier NX and Jetson Nano GPU devices. Extensive experiments demonstrate that the LWUAVDet models achieve a better tradeoff between accuracy and latency on VisDrone, UAVDT, and VOC2012 data sets compared to state-of-the-art lightweight models.},
  keywords={Autonomous aerial vehicles;Feature extraction;Internet of Things;Image edge detection;Object detection;Real-time systems;Edge devices;lightweight;object detection;real-time;unmanned aerial vehicles (UAVs)},
  doi={10.1109/JIOT.2024.3388045},
  ISSN={2327-4662},
  month={July},
  google_scholar_id={W7OEmFMy1HYC},
  selected=true}
---
@article{wang2024smart,
  title={Smart Expert System: Large Language Models as Text Classifiers},
  author={Wang, Zhiqiang and Pang, Yiran and Lin, Yanbin},
  journal={arXiv e-prints},
  pages={arXiv--2405},
  year={2024},
  abstract={Text classification is a fundamental task in Natural Language Processing (NLP), and the advent of Large Language Models (LLMs) has revolutionized the field. This paper introduces the Smart Expert System, a novel approach that leverages LLMs as text classifiers. The system simplifies the traditional text classification workflow, eliminating the need for extensive preprocessing and domain expertise. The performance of several LLMs, machine learning (ML) algorithms, and neural network (NN) based structures is evaluated on four datasets. Results demonstrate that certain LLMs surpass traditional methods in sentiment analysis, spam SMS detection and multi-label classification. Furthermore, it is shown that the system’s performance can be further enhanced through few-shot or fine-tuning strategies, making the fine-tuned model the top performer across all datasets. Source code and datasets are available in this GitHub repository: https://github.com/yeyimilk/llm-zero-shot-classifiers.},
  keywords={Large Language Models, Text Classification, Natural Language Processing, Smart Expert Systems, Few-Shot Learning, Fine-Tuning, Chat GPT-4, Llama3.},
  doi={10.48550/arXiv.2405.10523},
  google_scholar_id={YsMSGLbcyi4C},
  selected=true
}
---
@article{PANG2025129550,
title = {A fast federated reinforcement learning approach with phased weight-adjustment technique},
journal = {Neurocomputing},
volume = {626},
pages = {129550},
year = {2025},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2025.129550},
url = {https://www.sciencedirect.com/science/article/pii/S092523122500222X},
author = {Yiran Pang and Zhen Ni and Xiangnan Zhong},
keywords = {Federated reinforcement learning, Aggregation coefficient, Communication efficiency, Convergence speed, Environment heterogeneity, Value-clipping strategy},
abstract = {Federated reinforcement learning (FRL) enables multiple agents to learn collaboratively without directly sharing their local data. This method addresses the data privacy concerns in the distributed systems. However, FRL faces challenges such as high communication costs, since it requires extensive interactions to achieve satisfied performance. Therefore, this paper develops a fast FRL method with a dynamic aggregation coefficient to reduce the communication load during the learning process. Diverging from traditional FRL techniques which rely on static averaging, our approach begins by setting the initial aggregation coefficient to the logarithm of the number of participating agents. This elevation can enhance the early integration of updates from distributed agents and facilitate a rapid initial learning phase. As communications progress, the aggregation coefficient linearly decreases, transitioning to an average aggregation by the end of the specified interval. This gradual reduction aligns individual learning updates more closely over time, shifting towards a unified global learning model. Furthermore, we implement a value-clipping strategy to constrain global updates within a predefined safe range, thus safeguarding against the potential overflow issues. The aggregation coefficient stabilizes after the initial aggressive integration phase to ensure the training stability. The boundedness analysis of the model aggregation confirms that, despite the high initial coefficient, the parameters of the global model remain within the manageable limits on the FRL server. This strategy is applicable to both tabular and deep learning methods. We validate the designed algorithm on navigation and control tasks, including heterogeneous environments where distinct state transitions and dynamics are designed for each agent. The experimental results demonstrate that our proposed approach achieves faster convergence across various environments.},
google_scholar_id={eQOLeE2rZwMC},
selected=true}
---
@INPROCEEDINGS{10917961,
  author={Wang, Zhiqiang and Pang, Yiran and Lin, Yanbin and Zhu, Xingquan},
  booktitle={2024 IEEE International Conference on Data Mining Workshops (ICDMW)}, 
  title={Adaptable and Reliable Text Classification using Large Language Models}, 
  year={2024},
  volume={},
  number={},
  pages={67-74},
  abstract={Text classification is fundamental in Natural Language Processing (NLP), and the advent of Large Language Models (LLMs) has revolutionized the field. This paper introduces an adaptable and reliable text classification paradigm, which leverages LLMs as the core component to address text classification tasks. Our system simplifies the traditional text classification workflows, reducing the need for extensive preprocessing and domain-specific expertise to deliver adaptable and reliable text classification results. We evaluated the performance of several LLMs, machine learning algorithms, and neural network-based architectures on four diverse datasets. Results demonstrate that certain LLMs surpass traditional methods in sentiment analysis, spam SMS detection, and multi-label classification. Furthermore, it is shown that the system’s performance can be further enhanced through few-shot or fine-tuning strategies, making the fine-tuned model the top performer across all datasets. Source code and datasets are available in this GitHub repository: https://github.com/yeyimilk/llm-zero-shot-classifiers.},
  keywords={Sentiment analysis;Machine learning algorithms;Large language models;Source coding;Conferences;Text categorization;Multi label classification;Reliability;Data mining;Software development management;Large Language Models;Text Classification;Natural Language Processing;Adaptive Learning;Fine-Tuning;Chat GPT-4;Llama3},
  doi={10.1109/ICDMW65004.2024.00015},
  ISSN={2375-9259},
  month={Dec},
  google_scholar_id={WF5omc3nYNoC},
  selected=true}
---
@phdthesis{pang2022crowd,
  title={Crowd Density Analysis Method in Scenic Spot Based on Multi-Source Feature Fusion},
  author={Pang, Yiran},
  year={2022},
  school={Chongqing University of Science and Technology},
  doi={10.27854/d.cnki.gcqkj.2022.000179},
  selected=false
  }
---
@inproceedings{pang2025integration,
  title={Integration of a new layer normalization process into federated reinforcement learning for environments with heterogeneous attribute spaces},
  author={Pang, Yiran and Ni, Zhen and Zhong, Xiangnan},
  booktitle={Artificial Intelligence and Machine Learning for Multi-Domain Operations Applications VII, SPIE},
  volume={13473},
  pages={246--253},
  year={2025},
  organization={SPIE},
  abstract={Reinforcement learning method across multiple environments requires coordination across different domains, each with distinct conditions and resource constraints. The system must integrate information from various environments while ensuring data privacy and security. Federated reinforcement learning (FedRL) provides a practical distributed framework by enabling models to be trained without sharing raw data. This approach not only protects data privacy but also reduces communication overhead. However, applying FedRL still faces challenges. The heterogeneity among multiple environments often leads to data shifts, resulting in decreased performance after parameter aggregation. To address this instability, we incorporate layer normalization into FedRL framework. Each agent computes normalization statistics based on intermediate features within its neural network, and the server periodically aggregates the learnable affine transformation parameters from all agents. Agents then apply the global parameters to ensure consistent feature scaling and shifting. This approach mitigates the instability caused by distribution shifts in heterogeneous real-world environments. To evaluate our method, we design experiments that simulate real-world challenges by introducing random and designated color schemes in CarRacing to create heterogeneous settings. The results show that incorporating layer normalization into the FedRL framework accelerates training convergence and yields higher cumulative rewards in heterogeneous environments.},
  doi={10.1117/12.3053916},
  selected=true
}
---
@inproceedings{Pang2025Personalized,
  author={Pang, Yiran and Ni, Zhen and Zhong, Xiangnan},
  booktitle={2025 International Joint Conference on Neural Networks (IJCNN)},
  title={Personalized Observation Normalization for Federated Reinforcement Learning in Simulation Environments with Heterogeneity},
  year={2025},
  abstract={Federated reinforcement learning (FedRL) enables multiple agents to collaboratively train a global policy without sharing raw data, making it ideal for privacy-sensitive applications. However, FedRL faces challenges in heterogeneous environments where differing state-transition dynamics lead to non-identical input distributions and imbalanced parameter updates during aggregation. Therefore, this paper develops a personalized observation normalization (PON) method, allowing each agent to locally normalize raw state inputs using a continuously updated running mean and variance. This design ensures consistent scaling of local feature without overshadowing across agents during aggregation. Furthermore, we demonstrate that sharing normalization parameters across agents is ineffective due to the diverse local input distributions, which highlights the necessity of personalized statistics. Experiments on heterogeneous MuJoCo tasks show that our developed PON accelerates training and achieves superior performance compared to baseline methods. },
  keywords={Federated Reinforcement Learning, Heterogeneous Environments, Observation Normalization, Personalized Federated Reinforcement Learning, and Distribution Shift.},
  selected=true
}